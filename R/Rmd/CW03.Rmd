---
title: "CW03"
author: "Ralph"
date: "2020/8/26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Survival Analysis

The survival analysis is originally used in bioinfomatics. But the logic of this algorithm can also applied in many other cases, e.g., the risks of loans...

In order to review the usage of survival analysis, I will start my study in packages related to survival analysis at the beginning.

#### Basic elements of survival analysis

> Event (ususlly relapse, progression, or death)
> Survival time 
> Consoring (When the end of a subject can not be observed, we can use "+" to explain their life extention)

#### Data prepration

```{r load survival package}
library(survival)
library(survminer)
head(lung)
```


```{r surv_data}
Surv(lung$time, lung$status)
#Surv will translate the data into the consored data
```

#### Survival curve

```{r survival curve}
fit <- survfit(Surv(time, status) ~ ifelse(ph.karno>70, "high","low"), data = lung)
print(fit)
```


```{r summary}
summary(fit)$table
```


```{r points of survival curve}
d <- data.frame(time = fit$time,
                  n.risk = fit$n.risk,
                  n.event = fit$n.event,
                  n.censor = fit$n.censor,
                  surv = fit$surv,
                  upper = fit$upper,
                  lower = fit$lower
                  )
head(d)
```

#### Visualization

```{r actural survival}
ggsurvplot(
   fit,                     # survfit object with calculated statistics.
   pval = TRUE,             # show p-value of log-rank test.
   conf.int = TRUE,         # show confidence intervals for 
                            # point estimaes of survival curves.
   conf.int.style = "step",  # customize style of confidence intervals
   xlab = "Time in days",   # customize X axis label.
   break.time.by = 200,     # break X axis in time intervals by 200.
   ggtheme = theme_light(), # customize plot and risk table with a theme.
   risk.table = "abs_pct",  # absolute number and percentage at risk.
  risk.table.y.text.col = T,# colour risk table text annotations.
  risk.table.y.text = FALSE,# show bars instead of names in text annotations
                            # in legend of risk table.
  ncensor.plot = TRUE,      # plot the number of censored subjects at time t
  surv.median.line = "hv",  # add the median survival pointer.
  legend.labs = 
    c("Male", "Female"),    # change legend labels.
  palette = 
    c("#E7B800", "#2E9FDF") # custom color palettes.
)
```

We can also combine more variables into the models and visualize them together.

```{r risks}
fit2 <- survfit( Surv(time, status) ~ sex + rx + adhere,
                data = colon )

ggsurv <- ggsurvplot(fit2, fun = "event", conf.int = TRUE,
                     ggtheme = theme_bw())
   
ggsurv$plot +theme_bw() + 
  theme (legend.position = "right")+
  facet_grid(rx ~ adhere)
```

#### Modeling

```{r cox}
res.cox<-coxph(Surv(time,status)~sex,data=lung)

summary(res.cox)
```

```{r AFT}
res.reg = survreg(Surv(time, status)~sex, data = lung)
summary(res.reg)
```


#### Outcome integration

Normally, getting the coefficients of the model is not the end of our job, while the finishing of paper is. Therefore, we should format our outcome into the way Office or Latex can read. Here below are methods:

`xtable` is a package to translate the modeling outcome or data frame into the language LaTex, the most famous paper formatting software,  can read.

```{r xtable}
library(xtable)
mod1 = summary(res.reg)
xtable(mod1$table)

```

In additional to LaTeX, we use MS Office most frequently. Therefore, if we can turn outcome into the format of MS Office, we can use `flextable` to fix it. 

```{r flextable}
library(flextable)
mod2 = summary(res.cox)
xtable_to_flextable(xtable(mod2$coefficients)) %>% 
  width(width = 1.5) %>% 
  height(height = 1.5) %>% 
  align(align = "middle") 

```

So if we want to integrate content, pictures and tables into a particular file, we shall use `officer`~

```{r officer}
library(officer)

fit2 <- survfit( Surv(time, status) ~ sex + rx + adhere,
                data = colon )

ggsurv <- ggsurvplot(fit2, fun = "event", conf.int = TRUE,
                     ggtheme = theme_bw())
   
ggsurv = ggsurv$plot +theme_bw() + 
  theme (legend.position = "right")+
  facet_grid(rx ~ adhere)

cox_b = coxph(Surv(time, status) ~ sex + rx + adhere,
                data = colon )
mod3 = summary(cox_b)

coe_table = flextable(xtable(mod3$coefficients))

my_doc = read_docx() %>% # new a doc file
    body_add_par(value = "Survival Analysis--Cox model", style = "heading 1") %>%
  body_add_toc(level = 2) %>%
  body_add_break() %>%

  body_add_par(value = "Survival curve", style = "heading 2") %>%
  body_add_gg(value = ggsurv, style = "centered"  ) %>%

  body_add_par(value = "Coefficients estimate", style = "heading 1") %>%
  body_add_flextable(value = coe_table) %>%

  print(target = "body_add_demo.docx")


```

## Make R easier

Other than survival, I also want to introduce some packages to make R tour easier. The `rlist` helps faster arrange the data among the unstructured list. The `parallel` and the `foreach` help faster deal with complex loops. The `purrr` helps map functions and inputs efficiently. The `lambda.r` helps faster define functions. The `fuzzyjoin` helps join data frames on inexact matching.

### rlist

With `rlist`, we can 

```{r rlist1}
library(rlist)
x <- lapply(1:3, function(i) { c(a=i,b=i^2)})
df <- lapply(1:3, function(i) { data.frame(a=i,b=i^2,c=letters[i])})
list.do(x, rbind) # call a function with a list of arguments
```

```{r rlist2}
x <- list(a=NULL,b=list(x=NULL,y=character()),d=1,e=2)
list.clean(x, function(x) length(x) == 0L, TRUE) #clean a list according to a particular rule
```

```{r rlist3}
x <- list(data.frame(i=1:5,x=rnorm(5)),
data.frame(y=rnorm(5),z=rnorm(5)))
list.cbind(x) #bind the data.frame inside the list together (see also "list.rbind")
```

```{r rlist4}
x <- list(p1 = list(type='A',score=list(c1=10,c2=8)),
p2 = list(type='B',score=list(c1=9,c2=9)),
p3 = list(type='B',score=list(c1=9,c2=7)))
list.filter(x, type=='B', score$c2 >= 8)
```

```{r rlist5}
x <- list(p1 = list(type='A',score=list(c1=10,c2=8)),
p2 = list(type='B',score=list(c1=9,c2=9)),
p3 = list(type='B',score=list(c1=9,c2=7)))
list.map(x, min(score$c1,score$c2))
```

#### fuzzyjoin

`fuzzyjoin` is actually a package that help join data according to the distance between keys. The core functions are `regex_x_join`s and `stringdist_x_join`s. 

```{r fuzzyjoin}
library(fuzzyjoin)
library(dplyr)
load("~/conflicts.RData")
pair = regex_inner_join(insurance[is.na(insurance$a1)==F,],
                        insurance[is.na(insurance$a2)==F,],
                        by = c("MANF_NAME","BRAND_NAME","SUB_MODEL_NAME"))
head(pair)
```

```{r fuzzyjoin2}
pairb = stringdist_inner_join(insurance[is.na(insurance$a1)==F,],
                        insurance[is.na(insurance$a2)==F,],
                        by = c("MANF_NAME","BRAND_NAME","SUB_MODEL_NAME","sales"), 
                        max_dist = 2) %>% 
  select(MANF_NAME.x, BRAND_NAME.x, SUB_MODEL_NAME.x, sales.x,
         MANF_NAME.y, BRAND_NAME.y, SUB_MODEL_NAME.y, sales.y) %>% 
  .[.$sales.x==.$sales.y,]
head(pairb)
```

#### parallel

```{r parallel}
library(parallel)

clus = (detectCores()-1) %>% makeCluster() %>% makeCluster()
df <- data.frame(a=seq(1,10000,1),b=seq(10,100000,10),c=runif(100))
custom.function=function(x){a=(x[1]+x[2])*x[3];return(a)}
clusterExport(clus,"custom.function")
aa <- system.time({parRapply(clus,df, function(x) custom.function(x))})
stopCluster(clus)
```
#### foreach



##The FGD

### Problems of traditional research

#### It is highly influenced by the group of people
1. Group thinking
2. They cannot articulate themselves
3. What they say bias fro what they want
4. Limited knowledge
5. Due to the limitation of time, the subjects have to make quick decision
6. Make false link between factors and preference
7. To some extent, abstract!
8. How much will their opinions represent common sense?
9. Choose at random?



??? Why one of the subject can know more than the interviewer does?




## Deep-dive interview

### Start: self-intro

> job
> hobbies
> family
>> children
>> wife
> future planning
> opinions of friends
> focus-on areas (other than hobbies)
> automotive related
>> info source 
>> preference of auto
> frequent-used apps
>> social media
>>> followed people

### Automotive--Xiaopeng G3

> first/added car
> ICE/NEV (for commuting)
>> comparison
>>> BYD: the brand is poor
>>> Tesla: the interior is poor, the charging is inconvinient
>>> BMW 5: too big
>>> camry: too big
>>> Xiaopeng G3
> lead generation
>>> learnt from Douyin
>> preference
>>> SUV for family
>>> Manual gearbox is inconveinient
>>> SUV has more space
> criteria
>>> electrict-effective (G3 only lose 60 km range per 100 km while tesla will lose more than 100 km)
>>> power
>>> confort
>> new NEV brands
>>> Mayun's investment
>>> NEV focus is a plus
>>> it is state-of-the-art and more professional
>>> guarantee (better aftersales)
>>>> the aftersales experience is good
>>>> transparent
>>>> bought on showroom, while pick-up in another place (direct-sale)
>>>> road service is free
>>>> care-free service
>>>> valet car (xiaopeng) ### 
>>> other pros
>>>> quiet
>>>> built-in smart system (for Douyin, internet-music, novel reading)
>>>> smart interaction system

> brand (actually features)
>> Tesla
>>> the interior design is too simple
>>> good exterior design
>>> the pre-cursor
>> NIO
>>> the interior design is simple
>>> SUV orientation
>>> price is too high
>> Xiaopeng
>>> good-looking
>>> fulfill the expectation
>>> colorful helped functions shown in the test-drive:
>>>> smart auto-parking
>>>> 360 degree view
>>>> safety notice
>>>> remote manipulate
>>>> real-time CCTV
>>>> V2home
>>>> car-finding
>> WM (unknown)
>>> know after xiaopeng (I will not learn deeper)
>>> not as good-looking as xiaopeng
>>> cannot tell (I didn't learn WM before buying, I don't care anymore)

> Netx car purchasing
>> a car for playing
>>> P7 like panermera
>> a SUV for long-distanct running
>> banned to buy race-car by his wife

> feeling of NEV
>> the power is enough
>> people wonder about my xiaopeng ()
>>> outlook
>>> range (450 to 360)
>>> own a pile
>> focus on in-city transportation
>> for family-used

> highlights for xiaopeng
>> smart
>> electric-effective
>> power range
>> confort
>> high price-performance rate
>> good-looking
>> fast decision

> usage (the )
>> cons
>>> one small accident broke many things
>>> have no iqiy (need hardware updating)
>> inconvience
>> pros
>>> traffic jam
>>> auto-holding
>>> smart crusing (ACC)
>>> charging info
>>> air freshing
>>> 
>>> free data
>>>> 5G is a nice-to-have rather than a determing factor

>> configuration vs outlook?
>>> prefer configuration at first







